NEXT STEPS (PRIORITIZED)
========================

1) Semantic Layer + Metrics Registry
   - Introduce a thin semantic layer (YAML/JSON) that defines canonical metrics (e.g., AOV, revenue, repeat_rate), dimensions (customer_state, category), and time grains.
   - Force LLMs to target metrics by name → generate stable, lintable SQL via templates.
   - Benefit: stop bikeshedding metric definitions; fewer SQL bugs; faster iteration.

2) Multi-Turn SQL Refinement with Diffs
   - Keep the last successful SQL per chat; on follow-ups, generate a patch (diff) rather than fresh SQL.
   - Show a small “SQL diff” panel so users see exactly what changed.
   - Benefit: reduces hallucinations and preserves analyst intent across iterative questions.

3) Result Quality Gates + Golden Tests
   - Create a small suite of “golden queries” with expected row counts, schema, and simple invariants (e.g., no negative freight).
   - Auto-run after each LLM SQL generation; if a gate fails → trigger correction prompt before the user sees it.
   - Benefit: fewer embarrassing zero-row/garbage answers; measurable reliability.

4) Real RAG for Product Knowledge
   - Replace `fake_external_lookup` with a vector index over product catalog, help-center docs, and category glossaries.
   - Hybrid search (BM25 + dense) with source citations; retrieved facts are injected as system context for SQL generation.
   - Benefit: deeper category insights, grounded definitions, less LLM waffle.

5) Observability + Guardrails in Prod
   - Add structured logs (query text, model used, latency, cache hit, SQL len, row count), plus Prometheus metrics and simple dashboards.
   - Circuit breakers: back off Gemini/OpenRouter on sustained errors; auto-switch models; raise UI banner.
   - PII scrubber for logs; redact order_ids by default (toggleable for admins).
   - Benefit: you’ll actually know when/why it breaks—and you won’t leak data.
